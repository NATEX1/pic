import streamlit as st
import pandas as pd
import db

st.title(':red[‡∏Ñ‡∏≤‡∏ö]')
st.divider()
upload_data = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå", type=["csv", "xlsx"])

# ==================== CONFIG ====================
TABLE_NAME = "timeslot"
PRIMARY_KEY = "timeslot_id"
REQUIRED_COLS = ['timeslot_id', 'day', 'period', 'start', 'end']
DAY_TYPE_OPTIONS = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri']

# Column config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç timeslot_id ‡πÑ‡∏î‡πâ)
timeslot_columns_new = {
    "timeslot_id": st.column_config.TextColumn("‡∏£‡∏´‡∏±‡∏™‡∏Ñ‡∏≤‡∏ö", required=True),
    "day": st.column_config.SelectboxColumn("‡∏ß‡∏±‡∏ô", required=True, options=DAY_TYPE_OPTIONS),
    "period": st.column_config.NumberColumn("‡∏Ñ‡∏≤‡∏ö‡∏ó‡∏µ‡πà", required=True, min_value=1, max_value=20),
    "start": st.column_config.TextColumn("‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏° (HH:MM)", required=True),
    "end": st.column_config.TextColumn("‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î (HH:MM)", required=True),
}

# Column config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç (timeslot_id disabled)
timeslot_columns_edit = {
    "timeslot_id": st.column_config.TextColumn("‡∏£‡∏´‡∏±‡∏™‡∏Ñ‡∏≤‡∏ö", disabled=True),
    "day": st.column_config.SelectboxColumn("‡∏ß‡∏±‡∏ô", required=True, options=DAY_TYPE_OPTIONS),
    "period": st.column_config.NumberColumn("‡∏Ñ‡∏≤‡∏ö‡∏ó‡∏µ‡πà", required=True, min_value=1, max_value=20),
    "start": st.column_config.TextColumn("‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏° (HH:MM)", required=True),
    "end": st.column_config.TextColumn("‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î (HH:MM)", required=True),
}


# ==================== FUNCTIONS ====================
def fetch_timeslots():
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≤‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    return pd.DataFrame(db.fetch_all(f"SELECT * FROM {TABLE_NAME}"))


def convert_time_columns(df):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô string format HH:MM"""
    df = df.copy()
    for col in ['start', 'end']:
        if col in df.columns:
            # ‡∏Å‡∏£‡∏ì‡∏µ timedelta (‡∏à‡∏≤‡∏Å Excel)
            if pd.api.types.is_timedelta64_dtype(df[col]):
                df[col] = df[col].apply(lambda x: str(x).split()[-1][:5] if pd.notna(x) else '')
            # ‡∏Å‡∏£‡∏ì‡∏µ datetime
            elif pd.api.types.is_datetime64_any_dtype(df[col]):
                df[col] = df[col].dt.strftime('%H:%M')
            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏≠‡∏∑‡πà‡∏ô ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô string
            else:
                df[col] = df[col].astype(str).str.strip()
                # ‡∏ï‡∏±‡∏î seconds ‡∏≠‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡∏°‡∏µ (HH:MM:SS -> HH:MM)
                df[col] = df[col].apply(lambda x: x[:5] if len(x) >= 5 and ':' in x else x)
    return df


def validate_time_format(time_str):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ß‡∏•‡∏≤ HH:MM"""
    import re
    if pd.isna(time_str) or str(time_str).strip() == '':
        return False
    pattern = r'^([01]?[0-9]|2[0-3]):([0-5][0-9])$'
    return bool(re.match(pattern, str(time_str).strip()))


def validate_data(df, existing_ids=None):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    errors = []
    warnings = []

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö timeslot_id ‡∏ß‡πà‡∏≤‡∏á
    empty_mask = df['timeslot_id'].isna() | (df['timeslot_id'].astype(str).str.strip() == '')
    if empty_mask.any():
        errors.append(f"‚ùå ‡∏û‡∏ö timeslot_id ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ {empty_mask.sum()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö timeslot_id ‡∏ã‡πâ‡∏≥‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå
    duplicates = df[df.duplicated(subset=['timeslot_id'], keep=False) & ~empty_mask]
    if not duplicates.empty:
        errors.append(f"‚ùå ‡∏û‡∏ö timeslot_id ‡∏ã‡πâ‡∏≥‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå {len(duplicates)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö timeslot_id ‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
    if existing_ids is not None:
        existing_set = set(existing_ids)
        new_ids = set(df['timeslot_id'].dropna().astype(str).str.strip())
        conflicts = new_ids & existing_set
        if conflicts:
            errors.append(f"‚ùå ‡∏û‡∏ö timeslot_id ‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö: {', '.join(conflicts)}")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö day ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    invalid_days = ~df['day'].isin(DAY_TYPE_OPTIONS) & df['day'].notna()
    if invalid_days.any():
        bad_days = df.loc[invalid_days, 'day'].unique().tolist()
        errors.append(f"‚ùå ‡∏û‡∏ö‡∏ß‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {', '.join(map(str, bad_days))}")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö period ‡∏ß‡πà‡∏≤‡∏á
    empty_period = df['period'].isna()
    if empty_period.any():
        warnings.append(f"‚ö†Ô∏è ‡∏û‡∏ö period ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ {empty_period.sum()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ß‡∏•‡∏≤ start
    invalid_start = df['start'].apply(lambda x: not validate_time_format(x))
    if invalid_start.any():
        errors.append(f"‚ùå ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á {invalid_start.sum()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô HH:MM)")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ß‡∏•‡∏≤ end
    invalid_end = df['end'].apply(lambda x: not validate_time_format(x))
    if invalid_end.any():
        errors.append(f"‚ùå ‡∏û‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á {invalid_end.sum()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô HH:MM)")

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö start > end
    valid_times = ~invalid_start & ~invalid_end
    if valid_times.any():
        invalid_range = df[valid_times].apply(lambda row: row['start'] >= row['end'], axis=1)
        if invalid_range.any():
            errors.append(f"‚ùå ‡∏û‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î {invalid_range.sum()} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    return errors, warnings, duplicates


def clean_data(df):
    """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    df = df.copy()
    df['timeslot_id'] = df['timeslot_id'].astype(str).str.strip()
    df['day'] = df['day'].astype(str).str.strip()
    df['start'] = df['start'].astype(str).str.strip()
    df['end'] = df['end'].astype(str).str.strip()
    return df


# ==================== MAIN ====================
timeslots = fetch_timeslots()
if not timeslots.empty:
    timeslots = convert_time_columns(timeslots)
existing_ids = timeslots['timeslot_id'].tolist() if not timeslots.empty else []

# ==================== IMPORT SECTION ====================
if upload_data is not None:
    if upload_data.name.endswith('.csv'):
        df = pd.read_csv(upload_data)
    else:
        df = pd.read_excel(upload_data)

    missing_cols = [col for col in REQUIRED_COLS if col not in df.columns]
    if missing_cols:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {', '.join(missing_cols)}")
    else:
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ß‡∏•‡∏≤
        df = convert_time_columns(df)

        st.subheader("üìã Preview ‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

        edited_df = st.data_editor(
            df[REQUIRED_COLS],
            num_rows="dynamic",
            use_container_width=True,
            column_config=timeslot_columns_new,
            key="import_editor"
        )

        edited_df = clean_data(edited_df)
        errors, warnings, duplicates = validate_data(edited_df, existing_ids)

        st.info(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(edited_df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

        for warning in warnings:
            st.warning(warning)

        for error in errors:
            st.error(error)

        if not duplicates.empty:
            with st.expander("‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥"):
                st.dataframe(duplicates, column_config=timeslot_columns_new, use_container_width=True)

        can_save = len(errors) == 0 and len(edited_df) > 0

        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å", type="primary", disabled=not can_save, key="save_import"):
            try:
                sql = f"INSERT INTO {TABLE_NAME} (timeslot_id, day, period, start, end) VALUES (?, ?, ?, ?, ?)"
                count = 0
                for _, row in edited_df.iterrows():
                    if row['timeslot_id']:
                        db.execute(sql, (row['timeslot_id'], row['day'], row['period'], row['start'], row['end']))
                        count += 1
                st.success(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                st.balloons()
                st.rerun()
            except Exception as e:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

# ==================== EXISTING DATA SECTION ====================
st.divider()
if timeslots.empty:
    st.info("üì≠ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")
else:
    st.subheader(f"üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ({len(timeslots)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)")

    edited_timeslots = st.data_editor(
        timeslots,
        num_rows="dynamic",
        use_container_width=True,
        column_config=timeslot_columns_edit,
        key="existing_editor"
    )

    if not edited_timeslots.equals(timeslots):
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", type="primary"):
            try:
                for _, row in edited_timeslots.iterrows():
                    sql = f"UPDATE {TABLE_NAME} SET day=?, period=?, start=?, end=? WHERE timeslot_id=?"
                    db.execute(sql, (row['day'], row['period'], row['start'], row['end'], row['timeslot_id']))
                st.success("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                st.rerun()
            except Exception as e:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")